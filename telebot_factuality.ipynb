{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74bdf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb3b5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d57c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embed(tokens, i):\n",
    "    assert isinstance(tokens[0], str) # batch size 1\n",
    "    tokens = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\")\n",
    "    output = model(**tokens).last_hidden_state[0]\n",
    "    idx = [idx for idx, el in enumerate(tokens.word_ids()) if el == i]\n",
    "    vector = output[idx].mean(dim=0)\n",
    "    return vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd9190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([json.loads(el) for el in open(\"factuality_embed.jsonl\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba49c587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11196</th>\n",
       "      <td>[-0.3263489305973053, 0.12503716349601746, 0.0...</td>\n",
       "      <td>existing</td>\n",
       "      <td>2.25</td>\n",
       "      <td>train</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15391</th>\n",
       "      <td>[0.23019175231456757, -0.22958876192569733, 0....</td>\n",
       "      <td>said</td>\n",
       "      <td>3.00</td>\n",
       "      <td>train</td>\n",
       "      <td>4241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  vector      word  label  \\\n",
       "11196  [-0.3263489305973053, 0.12503716349601746, 0.0...  existing   2.25   \n",
       "15391  [0.23019175231456757, -0.22958876192569733, 0....      said   3.00   \n",
       "\n",
       "       split   idx  \n",
       "11196  train  2521  \n",
       "15391  train  4241  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b78e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.split.isin([\"train\", \"dev\"])]\n",
    "test = df[df.split.isin([\"test\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bba59dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.vstack(train.vector)\n",
    "y_train = train.label\n",
    "\n",
    "X_test = np.vstack(test.vector)\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65834a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58639d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip instalhttp://localhost:8888/notebooks/Desktop/%D0%BA%D1%83%D1%80%D1%81%D0%BE%D0%B2%D0%B0%D1%8F%203%20%D0%BA%D1%83%D1%80%D1%81/corpora/baseline%20(2)-Copy1.ipynb#l deep_translator\n",
    "#!python -m spacy download en_core_web_trf\n",
    "import spacy_transformers \n",
    "import spacy\n",
    "import en_core_web_trf\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "nlp = en_core_web_trf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57421d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "translator = GoogleTranslator(source='ru', target='en')\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def roots(sentence):\n",
    "  id = 0\n",
    "  roots = {}\n",
    "  for token in nlp(sentence):\n",
    "    if token.dep_ == 'ROOT':\n",
    "      roots[token.text] = id \n",
    "    id += 1\n",
    "\n",
    "    if roots:\n",
    "      target_id = 0\n",
    "      for root in roots:\n",
    "        span = [roots[root], roots[root] + 1]\n",
    "        target_id += 1\n",
    "        return span\n",
    "\n",
    "\n",
    "def translate(original):\n",
    "  translated = translator.translate(original, dest='en', src='ru')\n",
    "  return translated\n",
    "\n",
    "def embed(tokens, i):\n",
    "    assert isinstance(tokens[0], str) # batch size 1\n",
    "    tokens = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\")\n",
    "    output = model(**tokens).last_hidden_state[0]\n",
    "    idx = [idx for idx, el in enumerate(tokens.word_ids()) if el == i]\n",
    "    vector = output[idx].mean(dim=0)\n",
    "    return vector \n",
    "\n",
    "def get_factuality(sentence):\n",
    "    translated = translate(sentence)\n",
    "    index = roots(translated)\n",
    "    doc = nlp(translated)\n",
    "    translated = [w.text for w in doc]\n",
    "    print(translated, index)\n",
    "    factuality_score = reg.predict([embed(translated, index[0]).detach().numpy()])[0]\n",
    "    if factuality_score > 3:\n",
    "        factuality_score = 3.00\n",
    "    elif factuality_score < 0:\n",
    "        factuality_score *= 1.5\n",
    "    elif factuality_score < -1:\n",
    "        factuality_score *= 2\n",
    "    elif factuality_score < 2 and 'не' in sentence.split():\n",
    "        factuality_score -= 3\n",
    "    if factuality_score < -3:\n",
    "        factuality_score = -3.00\n",
    "\n",
    "    return round(factuality_score, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce6e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot\n",
    "\n",
    "botTimeWeb = telebot.TeleBot('6235401363:AAGKW404MvQMf_cSGSc1DNqSGWBCbfCk_Ks')\n",
    "\n",
    "from telebot import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c29af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "@botTimeWeb.message_handler(commands=['start'])\n",
    "def startBot(message):\n",
    "  first_mess = f\"Привет! Я умею предсказывать значение фактуальности предложений в тексте на <b>русском и английском языках</b>.\\n\\nФактуальность события выражает степень уверенности говорящего в достоверности той информации, которую он сообщает. Выражается фактуальность при помощи вещественного числа от <b>-3</b> до <b>3</b>, от непроизодшего события до достоверно случившегося соотвественно. В предложениях с несколькими сказуемыми модель будет определять значение <b>только для первого</b>.\\n\\nПодробнее о фактуальности и модели можно прочитать по команде /help.\\n\\nВведи своё предложение, чтобы начать.\"\n",
    "  markup = types.InlineKeyboardMarkup()\n",
    "  button_yes = types.InlineKeyboardButton(text = 'Да', callback_data='yes')\n",
    "  markup.add(button_yes)\n",
    "  markup = types.InlineKeyboardMarkup()\n",
    "  markup.add(types.InlineKeyboardButton(\"Cвязаться с автором.\", url=\"https://t.me/eapocs\"))\n",
    "  botTimeWeb.send_message(message.chat.id, first_mess, parse_mode='html', reply_markup=markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c906d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@botTimeWeb.message_handler(commands=['help'])\n",
    "def helpBot(message):\n",
    "    first_mess = f\"О чём я могу тебе рассказать?\"\n",
    "    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)\n",
    "    btn1 = types.KeyboardButton('Бот молчит')\n",
    "    btn2 = types.KeyboardButton(\"Немного теории\")\n",
    "    btn3 = types.KeyboardButton(\"Подробнее о модели\")\n",
    "    markup.add(btn1, btn2, btn3)\n",
    "    botTimeWeb.send_message(message.chat.id, first_mess, parse_mode='html', reply_markup=markup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4e5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@botTimeWeb.callback_query_handler(func=lambda call:True)\n",
    "def response(function_call):\n",
    "  if function_call.message:\n",
    "     if function_call.data == \"yes\":\n",
    "        second_mess = \"Введи своё предложение.\"\n",
    "        #markup = types.InlineKeyboardMarkup()\n",
    "        #markup.add(types.InlineKeyboardButton(\"Cвязаться с автором.\", url=\"https://t.me/eapocs\"))\n",
    "        botTimeWeb.send_message(function_call.message.chat.id, second_mess, reply_markup=markup)\n",
    "        botTimeWeb.answer_callback_query(function_call.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a002484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@botTimeWeb.message_handler(content_types=[\"text\"])\n",
    "def repeat_all_messages(message):\n",
    "    if(message.text == \"Бот молчит\"):\n",
    "        botTimeWeb.send_message(message.chat.id, parse_mode='html', text=\"Попробуй отправить предложение снова или введи другое предложение.\\n\\nБот может не отвечать на предложения, которые введены в некорректной форме. Предложения должны быть на русском или английском.\")\n",
    "    elif(message.text == \"Немного теории\"):\n",
    "        botTimeWeb.send_message(message.chat.id, parse_mode='html', text=\"Фактуальность — степень уверенности говорящего в том, что некоторое событие произошло. Вершиной события в предложении является сказуемое — именно для него определяется значение фактуальности.\\n\\nРазличные степени фактуальности могут выражаться разными способами, например:\\n— модальность (<i>Послышались всплески: <b>наверное</b>, это маленькая зелёная лягушка прыгает по лужам.</i>)\\n— дополнительный источник информации, или эвиденциальность (<i>Послышались всплески: <b>мальчик сказал</b>, что это маленькая зелёная лягушка прыгает по лужам.</i>)\\n— наклонение (условное наклонение (<i>бы</i>) и повелительное наклонение (<i>прыгай!</i>) получают отрицательное значение)\\n\\nПримеры:\\n<i>Лягушка <b>прыгала</b> по лужам</i> (3.0)\\n<i>Лягушка не <b>любит</b> прыгать по лужам</i> (-3.0)\\n<i>Вероятно, она <b>прыгнула</b> в лужу</i> (2.0)\\n<i>По их словам, лягушка <b>прыгает</b> по лужам без калош</i> (1.5)\")\n",
    "    elif(message.text == \"Подробнее о модели\"):\n",
    "        botTimeWeb.send_message(message.chat.id, parse_mode='html', text=\"Эта модель была обучена на корпусе текстов объёмом более 10 тысяч предложений. Корпус был переведён с английского языка. Текст на входе токенизируется и выделяется вершина предложения при помощи библиотеки <i>spacy</i>. Каждое предложение получает векторное представление при помощи мультиязычного <i>BERT-а</i>, затем этот вектор передаётся модели линейной регрессии, которая предсказывает численное значение фактуальности.\")\n",
    "    else:\n",
    "        factuality_score = get_factuality(message.text)\n",
    "        print(message.text, message.from_user.username, factuality_score)\n",
    "        botTimeWeb.send_message(message.chat.id, f'Значение фактуальности: {factuality_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b58077",
   "metadata": {},
   "outputs": [],
   "source": [
    "botTimeWeb.infinity_polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f3c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
